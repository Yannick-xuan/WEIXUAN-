{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":3680037,"sourceType":"datasetVersion","datasetId":2202288},{"sourceId":4988409,"sourceType":"datasetVersion","datasetId":2893282},{"sourceId":5632975,"sourceType":"datasetVersion","datasetId":3238926},{"sourceId":6146260,"sourceType":"datasetVersion","datasetId":3521629},{"sourceId":6146317,"sourceType":"datasetVersion","datasetId":3524699},{"sourceId":6149251,"sourceType":"datasetVersion","datasetId":3526632},{"sourceId":6170048,"sourceType":"datasetVersion","datasetId":3540267},{"sourceId":6272970,"sourceType":"datasetVersion","datasetId":3606194},{"sourceId":6287729,"sourceType":"datasetVersion","datasetId":3592933},{"sourceId":6300474,"sourceType":"datasetVersion","datasetId":3520954},{"sourceId":6301555,"sourceType":"datasetVersion","datasetId":3600418},{"sourceId":6327819,"sourceType":"datasetVersion","datasetId":3641955}],"dockerImageVersionId":30528,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notes\n\nBe sure to check out the original models linked here:\n\nOringinal Ensemble: https://www.kaggle.com/code/judith007/ensemble-score-boost-lb-0-763\nOriginal Models: https://www.kaggle.com/code/nlztrk/openbook-debertav3-large-baseline-single-model\nhttps://www.kaggle.com/code/hycloud/2023kagglellm-deberta-v3-large-model1-inference\n\nAnd of course no notebook would be complete for this competition at this moment without giving a shoutout to @radek1\n\nA number of improvements could still be made here really anywhere along the pipeline. A number of good discussions have come out regaurding prompt engineering, which would undoubtably increase data quality and thus the model scores. There could be other models added into the mix, I have seen a lot of deberta-v3-large and would expect to see some other big ones in there too. I would also suggest that voting ensemble is just 1 of many ways to make a submission and I would imagine that there are many other ways to make an even more successful version! Perhaps we will save that for later!","metadata":{}},{"cell_type":"code","source":"# installing offline dependencies\n!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n!pip install -U /kaggle/working/sentence-transformers\n!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n\n!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":126.809817,"end_time":"2023-08-14T10:09:22.925969","exception":false,"start_time":"2023-08-14T10:07:16.116152","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:35:59.113646Z","iopub.execute_input":"2023-08-22T16:35:59.114367Z","iopub.status.idle":"2023-08-22T16:37:50.872545Z","shell.execute_reply.started":"2023-08-22T16:35:59.114329Z","shell.execute_reply":"2023-08-22T16:37:50.871238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm.auto import tqdm\nimport blingfire as bf\nfrom __future__ import annotations\n\nfrom collections.abc import Iterable\n\nimport faiss\nfrom faiss import write_index, read_index\n\nfrom sentence_transformers import SentenceTransformer\n\nimport torch\nimport ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")","metadata":{"papermill":{"duration":8.534957,"end_time":"2023-08-14T10:09:31.474781","exception":false,"start_time":"2023-08-14T10:09:22.939824","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:37:50.878816Z","iopub.execute_input":"2023-08-22T16:37:50.879161Z","iopub.status.idle":"2023-08-22T16:37:54.82709Z","shell.execute_reply.started":"2023-08-22T16:37:50.87913Z","shell.execute_reply":"2023-08-22T16:37:54.826146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_documents(documents: Iterable[str],\n                      document_ids: Iterable,\n                      split_sentences: bool = True,\n                      filter_len: int = 3,\n                      disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Main helper function to process documents from the EMR.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param document_type: String denoting the document type to be processed\n    :param document_sections: List of sections for a given document type to process\n    :param split_sentences: Flag to determine whether to further split sections into sentences\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n    \n    df = sectionize_documents(documents, document_ids, disable_progress_bar)\n\n    if split_sentences:\n        df = sentencize(df.text.values, \n                        df.document_id.values,\n                        df.offset.values, \n                        filter_len, \n                        disable_progress_bar)\n    return df\n\n\ndef sectionize_documents(documents: Iterable[str],\n                         document_ids: Iterable,\n                         disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Obtains the sections of the imaging reports and returns only the \n    selected sections (defaults to FINDINGS, IMPRESSION, and ADDENDUM).\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `offset`\n    \"\"\"\n    processed_documents = []\n    for document_id, document in tqdm(zip(document_ids, documents), total=len(documents), disable=disable_progress_bar):\n        row = {}\n        text, start, end = (document, 0, len(document))\n        row['document_id'] = document_id\n        row['text'] = text\n        row['offset'] = (start, end)\n\n        processed_documents.append(row)\n\n    _df = pd.DataFrame(processed_documents)\n    if _df.shape[0] > 0:\n        return _df.sort_values(['document_id', 'offset']).reset_index(drop=True)\n    else:\n        return _df\n\n\ndef sentencize(documents: Iterable[str],\n               document_ids: Iterable,\n               offsets: Iterable[tuple[int, int]],\n               filter_len: int = 3,\n               disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Split a document into sentences. Can be used with `sectionize_documents`\n    to further split documents into more manageable pieces. Takes in offsets\n    to ensure that after splitting, the sentences can be matched to the\n    location in the original documents.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param offsets: Iterable tuple of the start and end indices\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n\n    document_sentences = []\n    for document, document_id, offset in tqdm(zip(documents, document_ids, offsets), total=len(documents), disable=disable_progress_bar):\n        try:\n            _, sentence_offsets = bf.text_to_sentences_and_offsets(document)\n            for o in sentence_offsets:\n                if o[1]-o[0] > filter_len:\n                    sentence = document[o[0]:o[1]]\n                    abs_offsets = (o[0]+offset[0], o[1]+offset[0])\n                    row = {}\n                    row['document_id'] = document_id\n                    row['text'] = sentence\n                    row['offset'] = abs_offsets\n                    document_sentences.append(row)\n        except:\n            continue\n    return pd.DataFrame(document_sentences)","metadata":{"papermill":{"duration":0.034054,"end_time":"2023-08-14T10:09:31.574046","exception":false,"start_time":"2023-08-14T10:09:31.539992","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:37:54.828503Z","iopub.execute_input":"2023-08-22T16:37:54.82958Z","iopub.status.idle":"2023-08-22T16:37:54.846316Z","shell.execute_reply.started":"2023-08-22T16:37:54.829542Z","shell.execute_reply":"2023-08-22T16:37:54.845452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIM_MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\nDEVICE = 0 #torch.device('cuda')\nMAX_LENGTH = 384\nBATCH_SIZE = 16\n\nWIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(WIKI_PATH)","metadata":{"papermill":{"duration":0.036342,"end_time":"2023-08-14T10:09:31.623595","exception":false,"start_time":"2023-08-14T10:09:31.587253","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:37:54.850748Z","iopub.execute_input":"2023-08-22T16:37:54.851027Z","iopub.status.idle":"2023-08-22T16:37:54.862419Z","shell.execute_reply.started":"2023-08-22T16:37:54.851002Z","shell.execute_reply":"2023-08-22T16:37:54.861421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Relevant Title Retrieval","metadata":{}},{"cell_type":"code","source":"trn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\").drop(\"id\", 1)\ntrn.head()","metadata":{"papermill":{"duration":0.058533,"end_time":"2023-08-14T10:09:31.695383","exception":false,"start_time":"2023-08-14T10:09:31.63685","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:37:54.864001Z","iopub.execute_input":"2023-08-22T16:37:54.864478Z","iopub.status.idle":"2023-08-22T16:37:54.896211Z","shell.execute_reply.started":"2023-08-22T16:37:54.864445Z","shell.execute_reply":"2023-08-22T16:37:54.895389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = SentenceTransformer(SIM_MODEL, device=torch.device('cuda'))\nmodel2.max_seq_length = MAX_LENGTH\nmodel2 = model2.half()","metadata":{"papermill":{"duration":13.282604,"end_time":"2023-08-14T10:09:44.992949","exception":false,"start_time":"2023-08-14T10:09:31.710345","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:37:54.898555Z","iopub.execute_input":"2023-08-22T16:37:54.899152Z","iopub.status.idle":"2023-08-22T16:38:02.648586Z","shell.execute_reply.started":"2023-08-22T16:37:54.899119Z","shell.execute_reply":"2023-08-22T16:38:02.647546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_index = read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")","metadata":{"papermill":{"duration":95.926417,"end_time":"2023-08-14T10:11:20.934445","exception":false,"start_time":"2023-08-14T10:09:45.008028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:38:02.650192Z","iopub.execute_input":"2023-08-22T16:38:02.650562Z","iopub.status.idle":"2023-08-22T16:39:38.54859Z","shell.execute_reply.started":"2023-08-22T16:38:02.650526Z","shell.execute_reply":"2023-08-22T16:39:38.543748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_embeddings = model2.encode(trn.prompt.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nprompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n_ = gc.collect()","metadata":{"papermill":{"duration":10.891104,"end_time":"2023-08-14T10:11:31.84869","exception":false,"start_time":"2023-08-14T10:11:20.957586","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:39:38.553906Z","iopub.execute_input":"2023-08-22T16:39:38.554391Z","iopub.status.idle":"2023-08-22T16:39:46.647662Z","shell.execute_reply.started":"2023-08-22T16:39:38.554345Z","shell.execute_reply":"2023-08-22T16:39:46.646653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the top 3 pages that are likely to contain the topic of interest\nsearch_score, search_index = sentence_index.search(prompt_embeddings, 3)","metadata":{"papermill":{"duration":23.339585,"end_time":"2023-08-14T10:11:55.247556","exception":false,"start_time":"2023-08-14T10:11:31.907971","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:39:46.650114Z","iopub.execute_input":"2023-08-22T16:39:46.650457Z","iopub.status.idle":"2023-08-22T16:40:09.72107Z","shell.execute_reply.started":"2023-08-22T16:39:46.650423Z","shell.execute_reply":"2023-08-22T16:40:09.719384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Save memory - delete sentence_index since it is no longer necessary\ndel sentence_index\ndel prompt_embeddings\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"papermill":{"duration":0.877305,"end_time":"2023-08-14T10:11:56.145444","exception":false,"start_time":"2023-08-14T10:11:55.268139","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:40:09.726512Z","iopub.execute_input":"2023-08-22T16:40:09.727524Z","iopub.status.idle":"2023-08-22T16:40:10.730094Z","shell.execute_reply.started":"2023-08-22T16:40:09.727469Z","shell.execute_reply":"2023-08-22T16:40:10.728826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting Sentences from the Relevant Titles","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\",\n                     columns=['id', 'file'])","metadata":{"papermill":{"duration":5.737408,"end_time":"2023-08-14T10:12:01.897408","exception":false,"start_time":"2023-08-14T10:11:56.16","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:40:10.732047Z","iopub.execute_input":"2023-08-22T16:40:10.732509Z","iopub.status.idle":"2023-08-22T16:40:16.411118Z","shell.execute_reply.started":"2023-08-22T16:40:10.732463Z","shell.execute_reply":"2023-08-22T16:40:16.409982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the article and associated file location using the index\nwikipedia_file_data = []\n\nfor i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n    scr_idx = idx\n    _df = df.loc[scr_idx].copy()\n    _df['prompt_id'] = i\n    wikipedia_file_data.append(_df)\nwikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\nwikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)\n\n## Save memory - delete df since it is no longer necessary\ndel df\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"papermill":{"duration":0.799872,"end_time":"2023-08-14T10:12:02.712752","exception":false,"start_time":"2023-08-14T10:12:01.91288","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:40:16.414893Z","iopub.execute_input":"2023-08-22T16:40:16.415237Z","iopub.status.idle":"2023-08-22T16:40:17.407827Z","shell.execute_reply.started":"2023-08-22T16:40:16.415207Z","shell.execute_reply":"2023-08-22T16:40:17.406665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the full text data\nwiki_text_data = []\n\nfor file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n    _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data['file']==file]['id'].tolist()]\n    _df = pd.read_parquet(f\"{WIKI_PATH}/{file}\", columns=['id', 'text'])\n\n    _df_temp = _df[_df['id'].isin(_id)].copy()\n    del _df\n    _ = gc.collect()\n    libc.malloc_trim(0)\n    wiki_text_data.append(_df_temp)\nwiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)\n_ = gc.collect()","metadata":{"papermill":{"duration":303.981049,"end_time":"2023-08-14T10:17:06.710072","exception":false,"start_time":"2023-08-14T10:12:02.729023","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:40:17.409323Z","iopub.execute_input":"2023-08-22T16:40:17.41002Z","iopub.status.idle":"2023-08-22T16:45:07.443143Z","shell.execute_reply.started":"2023-08-22T16:40:17.409982Z","shell.execute_reply":"2023-08-22T16:45:07.44193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Parse documents into sentences\nprocessed_wiki_text_data = process_documents(wiki_text_data.text.values, wiki_text_data.id.values)","metadata":{"papermill":{"duration":4.491281,"end_time":"2023-08-14T10:17:11.220342","exception":false,"start_time":"2023-08-14T10:17:06.729061","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:07.452772Z","iopub.execute_input":"2023-08-22T16:45:07.453122Z","iopub.status.idle":"2023-08-22T16:45:12.104069Z","shell.execute_reply.started":"2023-08-22T16:45:07.453091Z","shell.execute_reply":"2023-08-22T16:45:12.102933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get embeddings of the wiki text data\nwiki_data_embeddings = model2.encode(processed_wiki_text_data.text,\n                                    batch_size=BATCH_SIZE,\n                                    device=DEVICE,\n                                    show_progress_bar=True,\n                                    convert_to_tensor=True,\n                                    normalize_embeddings=True)#.half()\nwiki_data_embeddings = wiki_data_embeddings.detach().cpu().numpy()","metadata":{"papermill":{"duration":25.110593,"end_time":"2023-08-14T10:17:36.348422","exception":false,"start_time":"2023-08-14T10:17:11.237829","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:12.105701Z","iopub.execute_input":"2023-08-22T16:45:12.106344Z","iopub.status.idle":"2023-08-22T16:45:38.550394Z","shell.execute_reply.started":"2023-08-22T16:45:12.106303Z","shell.execute_reply":"2023-08-22T16:45:38.549057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = gc.collect()","metadata":{"papermill":{"duration":0.315807,"end_time":"2023-08-14T10:17:36.679867","exception":false,"start_time":"2023-08-14T10:17:36.36406","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:38.552421Z","iopub.execute_input":"2023-08-22T16:45:38.552907Z","iopub.status.idle":"2023-08-22T16:45:38.933088Z","shell.execute_reply.started":"2023-08-22T16:45:38.552864Z","shell.execute_reply":"2023-08-22T16:45:38.931846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Combine all answers\ntrn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\n\n\n## Search using the prompt and answers to guide the search\ntrn['prompt_answer_stem'] = trn['prompt'] + \" \" + trn['answer_all']","metadata":{"papermill":{"duration":0.034767,"end_time":"2023-08-14T10:17:36.730378","exception":false,"start_time":"2023-08-14T10:17:36.695611","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:38.934852Z","iopub.execute_input":"2023-08-22T16:45:38.936529Z","iopub.status.idle":"2023-08-22T16:45:38.955801Z","shell.execute_reply.started":"2023-08-22T16:45:38.936495Z","shell.execute_reply":"2023-08-22T16:45:38.954559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:45:38.958038Z","iopub.execute_input":"2023-08-22T16:45:38.959151Z","iopub.status.idle":"2023-08-22T16:45:38.985815Z","shell.execute_reply.started":"2023-08-22T16:45:38.959105Z","shell.execute_reply":"2023-08-22T16:45:38.984468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question_embeddings = model2.encode(trn.prompt_answer_stem.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nquestion_embeddings = question_embeddings.detach().cpu().numpy()","metadata":{"papermill":{"duration":0.431343,"end_time":"2023-08-14T10:17:37.177862","exception":false,"start_time":"2023-08-14T10:17:36.746519","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:38.987654Z","iopub.execute_input":"2023-08-22T16:45:38.98836Z","iopub.status.idle":"2023-08-22T16:45:39.37771Z","shell.execute_reply.started":"2023-08-22T16:45:38.988315Z","shell.execute_reply":"2023-08-22T16:45:39.376495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Matching Prompt-Sentence Pairs","metadata":{}},{"cell_type":"code","source":"## Parameter to determine how many relevant sentences to include\nNUM_SENTENCES_INCLUDE = 5\n\n## List containing just Context\ncontexts = []\n\nfor r in tqdm(trn.itertuples(), total=len(trn)):\n\n    prompt_id = r.Index\n\n    prompt_indices = processed_wiki_text_data[processed_wiki_text_data['document_id'].isin(wikipedia_file_data[wikipedia_file_data['prompt_id']==prompt_id]['id'].values)].index.values\n\n    if prompt_indices.shape[0] > 0:\n        prompt_index = faiss.index_factory(wiki_data_embeddings.shape[1], \"Flat\")\n        prompt_index.add(wiki_data_embeddings[prompt_indices])\n\n        context = \"\"\n        \n        ## Get the top matches\n        ss, ii = prompt_index.search(question_embeddings, NUM_SENTENCES_INCLUDE)\n        for _s, _i in zip(ss[prompt_id], ii[prompt_id]):\n            context += processed_wiki_text_data.loc[prompt_indices]['text'].iloc[_i] + \" \"\n        \n    contexts.append(context)","metadata":{"papermill":{"duration":1.609553,"end_time":"2023-08-14T10:17:38.836268","exception":false,"start_time":"2023-08-14T10:17:37.226715","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:39.379587Z","iopub.execute_input":"2023-08-22T16:45:39.38036Z","iopub.status.idle":"2023-08-22T16:45:40.999481Z","shell.execute_reply.started":"2023-08-22T16:45:39.380316Z","shell.execute_reply":"2023-08-22T16:45:40.998712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn['context'] = contexts","metadata":{"papermill":{"duration":0.024188,"end_time":"2023-08-14T10:17:38.878394","exception":false,"start_time":"2023-08-14T10:17:38.854206","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:41.002934Z","iopub.execute_input":"2023-08-22T16:45:41.003879Z","iopub.status.idle":"2023-08-22T16:45:41.010065Z","shell.execute_reply.started":"2023-08-22T16:45:41.003836Z","shell.execute_reply":"2023-08-22T16:45:41.008728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn[[\"prompt\", \"context\", \"A\", \"B\", \"C\", \"D\", \"E\"]].to_csv(\"./test_context.csv\", index=False)","metadata":{"papermill":{"duration":0.050945,"end_time":"2023-08-14T10:17:38.944423","exception":false,"start_time":"2023-08-14T10:17:38.893478","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:41.011871Z","iopub.execute_input":"2023-08-22T16:45:41.012277Z","iopub.status.idle":"2023-08-22T16:45:41.043617Z","shell.execute_reply.started":"2023-08-22T16:45:41.01224Z","shell.execute_reply":"2023-08-22T16:45:41.042689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:45:41.045185Z","iopub.execute_input":"2023-08-22T16:45:41.045495Z","iopub.status.idle":"2023-08-22T16:45:41.063654Z","shell.execute_reply.started":"2023-08-22T16:45:41.045463Z","shell.execute_reply":"2023-08-22T16:45:41.062443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.015828,"end_time":"2023-08-14T10:17:39.007683","exception":false,"start_time":"2023-08-14T10:17:38.991855","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_dir = \"/kaggle/input/llm-se-debertav3-large\"","metadata":{"papermill":{"duration":0.023448,"end_time":"2023-08-14T10:17:39.047454","exception":false,"start_time":"2023-08-14T10:17:39.024006","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:41.065716Z","iopub.execute_input":"2023-08-22T16:45:41.066459Z","iopub.status.idle":"2023-08-22T16:45:41.071087Z","shell.execute_reply.started":"2023-08-22T16:45:41.066424Z","shell.execute_reply":"2023-08-22T16:45:41.069992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import Optional, Union\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy","metadata":{"papermill":{"duration":0.488286,"end_time":"2023-08-14T10:17:39.551173","exception":false,"start_time":"2023-08-14T10:17:39.062887","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:41.072811Z","iopub.execute_input":"2023-08-22T16:45:41.073231Z","iopub.status.idle":"2023-08-22T16:45:41.4733Z","shell.execute_reply.started":"2023-08-22T16:45:41.073199Z","shell.execute_reply":"2023-08-22T16:45:41.472361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"test_context.csv\")\ntest_df.index = list(range(len(test_df)))\ntest_df.id = list(range(len(test_df)))\ntest_df[\"prompt\"] = test_df[\"context\"] + \" #### \" +  test_df[\"prompt\"]","metadata":{"papermill":{"duration":0.037633,"end_time":"2023-08-14T10:17:39.605345","exception":false,"start_time":"2023-08-14T10:17:39.567712","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:41.474797Z","iopub.execute_input":"2023-08-22T16:45:41.475905Z","iopub.status.idle":"2023-08-22T16:45:41.493919Z","shell.execute_reply.started":"2023-08-22T16:45:41.475866Z","shell.execute_reply":"2023-08-22T16:45:41.492961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['answer'] = 'A'\ntest_ds = Dataset.from_pandas(test_df)","metadata":{"papermill":{"duration":0.030584,"end_time":"2023-08-14T10:17:39.651668","exception":false,"start_time":"2023-08-14T10:17:39.621084","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:41.495431Z","iopub.execute_input":"2023-08-22T16:45:41.495822Z","iopub.status.idle":"2023-08-22T16:45:41.509772Z","shell.execute_reply.started":"2023-08-22T16:45:41.495786Z","shell.execute_reply":"2023-08-22T16:45:41.508654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel2 = AutoModelForMultipleChoice.from_pretrained(model_dir)\nmodel2.eval()","metadata":{"papermill":{"duration":21.360878,"end_time":"2023-08-14T10:18:01.027859","exception":false,"start_time":"2023-08-14T10:17:39.666981","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:45:41.511473Z","iopub.execute_input":"2023-08-22T16:45:41.5119Z","iopub.status.idle":"2023-08-22T16:46:04.427527Z","shell.execute_reply.started":"2023-08-22T16:45:41.511866Z","shell.execute_reply":"2023-08-22T16:46:04.426231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef predictions_to_map_output(predictions):\n    sorted_answer_indices = np.argsort(-predictions)\n    top_answer_indices = sorted_answer_indices[:,:3] # Get the first three answers in each row\n    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)","metadata":{"papermill":{"duration":0.033179,"end_time":"2023-08-14T10:18:01.087489","exception":false,"start_time":"2023-08-14T10:18:01.05431","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:46:04.429353Z","iopub.execute_input":"2023-08-22T16:46:04.429784Z","iopub.status.idle":"2023-08-22T16:46:04.436845Z","shell.execute_reply.started":"2023-08-22T16:46:04.429747Z","shell.execute_reply":"2023-08-22T16:46:04.435496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\noptions = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(example):\n    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n    # so we'll copy our question 5 times before tokenizing\n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    # Our tokenizer will turn our text into token IDs BERT can understand\n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example","metadata":{"papermill":{"duration":0.026162,"end_time":"2023-08-14T10:18:01.129276","exception":false,"start_time":"2023-08-14T10:18:01.103114","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:46:04.438417Z","iopub.execute_input":"2023-08-22T16:46:04.43942Z","iopub.status.idle":"2023-08-22T16:46:04.452821Z","shell.execute_reply.started":"2023-08-22T16:46:04.439378Z","shell.execute_reply":"2023-08-22T16:46:04.451565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"papermill":{"duration":0.030447,"end_time":"2023-08-14T10:18:01.175589","exception":false,"start_time":"2023-08-14T10:18:01.145142","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:46:04.454933Z","iopub.execute_input":"2023-08-22T16:46:04.455924Z","iopub.status.idle":"2023-08-22T16:46:04.467945Z","shell.execute_reply.started":"2023-08-22T16:46:04.455881Z","shell.execute_reply":"2023-08-22T16:46:04.466588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model2,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer)\n)","metadata":{"papermill":{"duration":0.493618,"end_time":"2023-08-14T10:18:01.685989","exception":false,"start_time":"2023-08-14T10:18:01.192371","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:46:04.469607Z","iopub.execute_input":"2023-08-22T16:46:04.470057Z","iopub.status.idle":"2023-08-22T16:46:05.211422Z","shell.execute_reply.started":"2023-08-22T16:46:04.470021Z","shell.execute_reply":"2023-08-22T16:46:05.209601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_ds = test_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])","metadata":{"papermill":{"duration":1.101895,"end_time":"2023-08-14T10:18:02.804298","exception":false,"start_time":"2023-08-14T10:18:01.702403","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:46:05.21687Z","iopub.execute_input":"2023-08-22T16:46:05.218022Z","iopub.status.idle":"2023-08-22T16:46:06.567766Z","shell.execute_reply.started":"2023-08-22T16:46:05.217975Z","shell.execute_reply":"2023-08-22T16:46:06.566727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = trainer.predict(tokenized_test_ds)","metadata":{"papermill":{"duration":74.862571,"end_time":"2023-08-14T10:19:17.683318","exception":false,"start_time":"2023-08-14T10:18:02.820747","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:46:06.569589Z","iopub.execute_input":"2023-08-22T16:46:06.570369Z","iopub.status.idle":"2023-08-22T16:47:13.719667Z","shell.execute_reply.started":"2023-08-22T16:46:06.570327Z","shell.execute_reply":"2023-08-22T16:47:13.718554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(test_predictions.predictions))\ntest_predictions.predictions","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:47:13.721305Z","iopub.execute_input":"2023-08-22T16:47:13.72203Z","iopub.status.idle":"2023-08-22T16:47:13.74803Z","shell.execute_reply.started":"2023-08-22T16:47:13.72199Z","shell.execute_reply":"2023-08-22T16:47:13.746756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Optional, Union\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel\nfrom torch.utils.data import DataLoader\n\ndeberta_v3_large = '/kaggle/input/deberta-v3-large-hf-weights'","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:47:13.749653Z","iopub.execute_input":"2023-08-22T16:47:13.750485Z","iopub.status.idle":"2023-08-22T16:47:13.757551Z","shell.execute_reply.started":"2023-08-22T16:47:13.750445Z","shell.execute_reply":"2023-08-22T16:47:13.756528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_preds = torch.tensor(test_predictions.predictions)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:47:13.759597Z","iopub.execute_input":"2023-08-22T16:47:13.760302Z","iopub.status.idle":"2023-08-22T16:47:13.782263Z","shell.execute_reply.started":"2023-08-22T16:47:13.760243Z","shell.execute_reply":"2023-08-22T16:47:13.780952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\n\ndef preprocess(example):\n    first_sentence = [example['prompt']] * 5\n    second_sentences = [example[option] for option in 'ABCDE']\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation=False)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    \n    return tokenized_example\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch ","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:47:13.784234Z","iopub.execute_input":"2023-08-22T16:47:13.784803Z","iopub.status.idle":"2023-08-22T16:47:13.801859Z","shell.execute_reply.started":"2023-08-22T16:47:13.784753Z","shell.execute_reply":"2023-08-22T16:47:13.800635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(deberta_v3_large)\n\ntest_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\ntest_df['answer'] = 'A' # dummy answer that allows us to preprocess the test datataset using functionality that works for the train set\n\ntokenized_test_dataset = Dataset.from_pandas(test_df.drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\ntest_dataloader = DataLoader(tokenized_test_dataset, 10, shuffle=False, collate_fn=data_collator)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:47:13.8037Z","iopub.execute_input":"2023-08-22T16:47:13.804744Z","iopub.status.idle":"2023-08-22T16:47:15.570401Z","shell.execute_reply.started":"2023-08-22T16:47:13.804704Z","shell.execute_reply":"2023-08-22T16:47:15.569346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_preds_my_runs = []\nfor i in range(3):\n    model = AutoModelForMultipleChoice.from_pretrained(f'/kaggle/input/science-exam-trained-model-weights/run_{i}').cuda()\n    model.eval()\n    preds = []\n    for batch in test_dataloader:\n        for k in batch.keys():\n            batch[k] = batch[k].cuda()\n        with torch.no_grad():\n            outputs = model(**batch)\n        preds.append(outputs.logits.cpu().detach())\n\n    preds = torch.cat(preds)\n    all_preds_my_runs.append(preds)\n\nall_preds_my_runs = torch.stack(all_preds_my_runs)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:47:15.572031Z","iopub.execute_input":"2023-08-22T16:47:15.573152Z","iopub.status.idle":"2023-08-22T16:48:56.212276Z","shell.execute_reply.started":"2023-08-22T16:47:15.573116Z","shell.execute_reply":"2023-08-22T16:48:56.210163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForMultipleChoice.from_pretrained(f'/kaggle/input/2023kagglellm-deberta-v3-large-model1').cuda()\nmodel.eval()\npreds = []\nfor batch in test_dataloader:\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    preds.append(outputs.logits.cpu().detach())\n\nhyc_preds = torch.cat(preds)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:48:56.213849Z","iopub.execute_input":"2023-08-22T16:48:56.214152Z","iopub.status.idle":"2023-08-22T16:49:32.181771Z","shell.execute_reply.started":"2023-08-22T16:48:56.214126Z","shell.execute_reply":"2023-08-22T16:49:32.180575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForMultipleChoice.from_pretrained(f'/kaggle/input/my-1-epoch').cuda()\nmodel.eval()\npreds = []\nfor batch in test_dataloader:\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    preds.append(outputs.logits.cpu().detach())\n\nkb_preds = torch.cat(preds)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:49:32.183558Z","iopub.execute_input":"2023-08-22T16:49:32.184001Z","iopub.status.idle":"2023-08-22T16:50:04.080724Z","shell.execute_reply.started":"2023-08-22T16:49:32.183959Z","shell.execute_reply":"2023-08-22T16:50:04.079533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds_my_runs.shape, hyc_preds.shape, kb_preds.shape, best_preds.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:50:04.082329Z","iopub.execute_input":"2023-08-22T16:50:04.083017Z","iopub.status.idle":"2023-08-22T16:50:04.091061Z","shell.execute_reply.started":"2023-08-22T16:50:04.08296Z","shell.execute_reply":"2023-08-22T16:50:04.089933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\nvoting_ensemble = defaultdict(list)\n\nfor i_preds in range(all_preds_my_runs.shape[0]):\n    for row in range(all_preds_my_runs.shape[1]):\n        preds = all_preds_my_runs[i_preds][row]\n        voting_ensemble[row].append(preds.argsort(descending=True)[:3])","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:50:04.108103Z","iopub.execute_input":"2023-08-22T16:50:04.110665Z","iopub.status.idle":"2023-08-22T16:50:04.1367Z","shell.execute_reply.started":"2023-08-22T16:50:04.110625Z","shell.execute_reply":"2023-08-22T16:50:04.135654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for row in range(hyc_preds.shape[0]):\n    preds = hyc_preds[row]\n    voting_ensemble[row].append(preds.argsort(descending=True)[:3])","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:50:04.138761Z","iopub.execute_input":"2023-08-22T16:50:04.139564Z","iopub.status.idle":"2023-08-22T16:50:04.15044Z","shell.execute_reply.started":"2023-08-22T16:50:04.139509Z","shell.execute_reply":"2023-08-22T16:50:04.149299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for row in range(kb_preds.shape[0]):\n    preds = kb_preds[row]\n    voting_ensemble[row].append(preds.argsort(descending=True)[:3])","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:50:04.152766Z","iopub.execute_input":"2023-08-22T16:50:04.153843Z","iopub.status.idle":"2023-08-22T16:50:04.163634Z","shell.execute_reply.started":"2023-08-22T16:50:04.153804Z","shell.execute_reply":"2023-08-22T16:50:04.162843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for row in range(best_preds.shape[0]):\n    preds = best_preds[row]\n    voting_ensemble[row].append(preds.argsort(descending=True)[:3])","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:50:04.165599Z","iopub.execute_input":"2023-08-22T16:50:04.166627Z","iopub.status.idle":"2023-08-22T16:50:04.175791Z","shell.execute_reply.started":"2023-08-22T16:50:04.166591Z","shell.execute_reply":"2023-08-22T16:50:04.17484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor i_preds in range(all_preds_my_runs.shape[1]):\n    # 3 model from \n    votes = defaultdict(lambda: 0)\n    for preds in voting_ensemble[i_preds][:3]:\n        votes[preds[0].item()] += 4\n        votes[preds[1].item()] += 2\n        votes[preds[2].item()] += 1\n        \n    hyc_preds = voting_ensemble[i_preds][3]\n    votes[hyc_preds[0].item()] += 4 * 3.1\n    votes[hyc_preds[1].item()] += 2 * 2.9 \n    votes[hyc_preds[2].item()] += 1 * 2.9 \n    \n    kb_preds = voting_ensemble[i_preds][4]\n    votes[kb_preds[0].item()] += 4 * 3.0\n    votes[kb_preds[1].item()] += 2 * 3.0 \n    votes[kb_preds[2].item()] += 1 * 3.0 \n    \n    best_preds = voting_ensemble[i_preds][5]\n    votes[best_preds[0].item()] += 4 * 3.2\n    votes[best_preds[1].item()] += 2 * 3.0 \n    votes[best_preds[2].item()] += 1 * 3.0 \n    \n    predictions.append([t[0] for t in sorted(votes.items(), key=lambda x:x[1], reverse=True)][:3])","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:50:04.177625Z","iopub.execute_input":"2023-08-22T16:50:04.178526Z","iopub.status.idle":"2023-08-22T16:50:04.204483Z","shell.execute_reply.started":"2023-08-22T16:50:04.17849Z","shell.execute_reply":"2023-08-22T16:50:04.203317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[:5]","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:50:04.20583Z","iopub.execute_input":"2023-08-22T16:50:04.20621Z","iopub.status.idle":"2023-08-22T16:50:04.213688Z","shell.execute_reply.started":"2023-08-22T16:50:04.206173Z","shell.execute_reply":"2023-08-22T16:50:04.212583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_as_answer_letters = np.array(list('ABCDE'))[predictions]\npredictions_as_answer_letters[:3]","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:50:04.215551Z","iopub.execute_input":"2023-08-22T16:50:04.216381Z","iopub.status.idle":"2023-08-22T16:50:04.228273Z","shell.execute_reply.started":"2023-08-22T16:50:04.216341Z","shell.execute_reply":"2023-08-22T16:50:04.227083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_as_string = test_df['prediction'] = [\n    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n]\npredictions_as_string[:3]","metadata":{"execution":{"iopub.status.busy":"2023-08-22T16:50:04.230731Z","iopub.execute_input":"2023-08-22T16:50:04.231518Z","iopub.status.idle":"2023-08-22T16:50:04.24132Z","shell.execute_reply.started":"2023-08-22T16:50:04.231481Z","shell.execute_reply":"2023-08-22T16:50:04.239918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_df[['id', 'prediction']]\nsubmission.to_csv('submission.csv', index=False)\n\npd.read_csv('submission.csv').head()","metadata":{"papermill":{"duration":0.033576,"end_time":"2023-08-14T10:19:17.733491","exception":false,"start_time":"2023-08-14T10:19:17.699915","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-22T16:50:04.243919Z","iopub.execute_input":"2023-08-22T16:50:04.244394Z","iopub.status.idle":"2023-08-22T16:50:04.266053Z","shell.execute_reply.started":"2023-08-22T16:50:04.244353Z","shell.execute_reply":"2023-08-22T16:50:04.264741Z"},"trusted":true},"execution_count":null,"outputs":[]}]}